use clap::Parser;

use local_ip_address::local_ip;
use rand::Rng;
use serde::{Deserialize, Serialize};
use sha1::{Digest, Sha1};
use std::collections::HashMap;
use std::env;
use std::net::{IpAddr, Ipv4Addr, SocketAddr};
use tokio::net::UdpSocket;

// Number of bits for our IDs
const NUM_BITS: u32 = 6;
// Max number of entries in K-bucket
const K: u32 = 4;
// Max concurrent requests
const M: u32 = 3;

// node participating in DHT
// in our bittorrent implementations, peers are also nodes
#[derive(Debug)]
struct Node {
    id: u32,
    ip: IpAddr,
    port: u16,
    // is_good: bool, // responded to our query or requested a query within past 15 min,
}

// infohash of torrent = key id

// starts off with one bucket with ID space range 0 - 2^160
// when bucket full of known good nodes, no more nodes may be added unless our own ID falls within the range of the bucket
// -> in that case, bucket is replaced by 2 new buckets each with half the range of the old bucket
// -> and nodes from old bucket and distributed among two new ones
// for new table with 1 bucket, the full bucket is always split into two new buckets covering ranges 0..2^159 and 2^159..2^160
// if any nodes are **known** to be bad, it gets replaced by new node
//
// if questionable nodes not seen in the last 15 min, least recently seen is pinged
// -> until one fails to respond or all nodes are good
// -> but if fails to respond, try once more before discarding node and replacing with new good node
//
// need a "last changed" property for each bucket to indicate freshness
// -> when node is pinged and responds, when node is added to bucket, when node in a bucket is replaced with another node
//    -> the bucket last changed property should b e refreshed
//    -> by picking random id in the range of the bucket and run find_nodes
//    -> nodes that are able to receive queries from other nodes dno't need to refresh buckets often
//    -> but nodes that can't need to refresh periodically  so good nodes are available when DHT is needed
struct RoutingTable {
    // hashmap of linked lists
}

impl RoutingTable {
    fn new() {}

    fn upsert_node(node: &Node) {}
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug)]
struct KrpcRequest {
    t: String,
    y: String,

    q: String,
    a: HashMap<String, String>,
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug)]
struct KrpcSuccessResponse {
    t: String,
    y: String,

    r: HashMap<String, String>,
}

#[derive(Serialize, Deserialize, PartialEq, Eq, Debug)]
struct KrpcErrorResponse {
    t: String,
    y: String,

    e: (u8, String),
}

// KRPC - Bencoded dictionaries sent over UDP without retries
// dictionary with 3 keys common in all msgs and additional keys if needed
// t - transaction id
//      -> generated by the querying node and is echoed in the response
//      -> useful for correlation multiple queries to same node
//      -> short string of binary numbers, 2 characters are enough
// y - single char describing msg type (q for query, r for response, e for error)
// v - versioning (not needed rn)
//
// query:
//      key q - string value containing method name of query
//      key a - named arguments dict
// responses - key r, value is dictionary containing named return values
// errors - key e is a list, first element error code, second element string containing the error message

enum KrpcError {
    // 201
    GenericError,
    // 202
    ServerError,
    // 203
    ProtocolError,
    // 204
    MethodUnknown,
}

// All queries have id key and value containing node id of querying node
// Responses have same for responding node
enum DhtMessageType {
    // q = "ping", id = 20 byte string source id
    // Query = {"t":"aa", "y":"q", "q":"ping", "a":{"id":"abcdefghij0123456789"}}
    // Response = {"t":"aa", "y":"r", "r": {"id":"mnopqrstuvwxyz123456"}}
    Ping,
    // q = "find_node", id = source node id, target = target node id
    // return compact node info OR k closest good nodes in its own routing table
    FindNode,
    // q = "get_peers", id = source, info_hash = basically key id
    // If queried node has the val, return in "values" list
    // Else return "nodes" list with K nodes closest to infohash.
    // "token" short binary string included in return value TODO: what is this for?
    // format:
    // arguments:  {"id" : "<querying nodes id>", "info_hash" : "<20-byte infohash of target torrent>"}
    // response: {"id" : "<queried nodes id>", "token" :"<opaque write token>", "values" : ["<peer 1 info string>", "<peer 2 info string>"]}
    // or: {"id" : "<queried nodes id>", "token" :"<opaque write token>", "nodes" : "<compact node info>"}
    GetPeers,
    // q = "announce_peer", id = source, info_hash = key, port = udp port, token = received in response to previous get_peers query
    // response: {"id" : "<queried nodes id>"}
    AnnouncePeer,
}

fn gen_trans_id() -> String {
    let mut rng = rand::thread_rng();
    let trans_id: u16 = rng.gen();
    format!("{:02x}", trans_id)
}

async fn handle_krpc_call(socket: &UdpSocket, buf: &[u8; 2048], len: usize, addr: SocketAddr) {
    let query: KrpcRequest = serde_bencode::from_bytes(&buf[..len]).unwrap();
    println!("Received {:#?} from {}", query, addr.to_string());

    match query.q.as_str() {
        "ping" => {
            let mut return_values = HashMap::new();
            return_values.insert("id".into(), "server".into());

            let response = KrpcSuccessResponse {
                y: "r".into(),
                t: query.t,
                r: return_values,
            };
            let response = serde_bencode::to_bytes(&response).unwrap();
            socket.send_to(&response, addr).await.unwrap();
        }
        "find_node" => {}
        "get_peers" => {}
        "announce_peer" => {}
        _ => {}
    };
}

async fn send_ping(socket: &UdpSocket, addr: &str) {
    let mut arguments = HashMap::new();
    arguments.insert("id".into(), "client".into());

    let ping_query = KrpcRequest {
        t: gen_trans_id(),
        y: "q".into(),
        q: "ping".into(),
        a: arguments,
    };
    let ping_query = serde_bencode::to_bytes(&ping_query).unwrap();
    socket.send_to(&ping_query, addr).await.unwrap();

    let mut buf = [0; 2048];
    let (amt, src) = socket.recv_from(&mut buf).await.unwrap();

    let response: KrpcSuccessResponse = serde_bencode::from_bytes(&buf[..amt]).unwrap();
    println!("Received {:#?} from {}", response, src);
}

#[derive(Parser, Debug)]
#[command(author, version, about, long_about = None)]
struct Args {
    #[arg(short, long)]
    port: u16,

    #[arg(short = 't', long = "test")]
    is_testing: bool,

    #[arg(long)]
    bootstrap: Option<String>,

    #[arg(long)]
    id: Option<u32>,
}

#[tokio::main]
async fn main() {
    let args = Args::parse();
    // assign random id for our node if not passed in
    let id = args.id.unwrap_or_else(|| {
        // wait could we just hash our IP???
        let mut rng = rand::thread_rng();
        rng.gen_range(0..64)
    });
    let ip = local_ip().unwrap();

    let our_node = Node {
        id,
        ip,
        port: args.port,
    };

    let socket = UdpSocket::bind(format!("127.0.0.1:{}", args.port))
        .await
        .unwrap();
    println!("Started DHT node on {:#?}", our_node);

    if args.is_testing {
        send_ping(&socket, "127.0.0.1:8080").await;
    }

    if let Some(bootstrap) = args.bootstrap {
        // 1. initialize k-bucket with another known node
        // 2. run find_nodes on itself to fill k-bucket table
        // 3. refresh k-buckets farther than bootstrap node with find_node on random key within range
    } else {
    }

    loop {
        let mut buf = [0; 2048];
        let (len, addr) = socket.recv_from(&mut buf).await.unwrap();
        handle_krpc_call(&socket, &buf, len, addr).await;
    }
}
